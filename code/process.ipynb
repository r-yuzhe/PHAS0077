{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f21c1a-06c0-4db5-b85d-2eb88831fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59554c42-5844-4329-815b-f8be7aef1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to check whether CAPE is in a profile\n",
    "#input: one line of data(string)\n",
    "#return: boolean value\n",
    "\n",
    "def find_cape(data):\n",
    "    if \"Convective Available Potential Energy: \" in data:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d988cc83-3741-42c9-b374-aed556259be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to strip data\n",
    "#input: one line of data(string)\n",
    "#return: data(string)\n",
    "\n",
    "def data_strip(data):\n",
    "    return data.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c6935b-ba63-43c3-beb3-9a908a3334f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the CAPE value from soup object\n",
    "# Args: soup(BeautifulSoup)\n",
    "# return: cape(float)\n",
    "\n",
    "def get_cape(soup):\n",
    "    cape=\"No value\"\n",
    "    cape1=soup.find_all('pre')[1].string\n",
    "    split_cape=cape1.splitlines()\n",
    "    strip_cape=list(map(data_strip,split_cape))\n",
    "    n=list(map(find_cape,strip_cape))\n",
    "    if True in n:\n",
    "        t=n.index(True)\n",
    "        cape_line=strip_cape[t]\n",
    "        index=cape_line.index(\":\")\n",
    "        cape=float(cape_line[index+2:])\n",
    "    return cape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e17582c-ee74-40c1-b4f2-29ca3b51ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to get the latitude from a profile\n",
    "#input: soup(Beautifulsoup)\n",
    "#return: latitude(float)\n",
    "\n",
    "def get_latitude(soup):\n",
    "    latitude='no value'\n",
    "    if soup!=0:\n",
    "        pre=soup.find_all('pre')\n",
    "        if pre:\n",
    "            cape1=soup.find_all('pre')[1].string\n",
    "            cape_data=' '.join(cape1.splitlines()[3].split())\n",
    "            t=''.join(cape_data.split(':',1)[:1])\n",
    "            if t=='Station latitude':\n",
    "                a=''.join(cape_data.split(':',1)[1:])\n",
    "                latitude=float(a.replace(\" \", \"\"))\n",
    "            else:\n",
    "                cape_data=' '.join(cape1.splitlines()[4].split())\n",
    "                a=''.join(cape_data.split(':',1)[1:])\n",
    "                latitude=float(a.replace(\" \", \"\"))\n",
    "    return latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e06a037-7371-4e12-ba9c-a598e6b8eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to get the longitude from a profile\n",
    "#input: soup(Beautifulsoup)\n",
    "#return: longitude(float)\n",
    "\n",
    "def get_longitude(soup):\n",
    "    longitude='no value'\n",
    "    if soup!=0:\n",
    "        pre=soup.find_all('pre')\n",
    "        if pre:\n",
    "            cape1=soup.find_all('pre')[1].string\n",
    "            cape_data=' '.join(cape1.splitlines()[4].split())\n",
    "            t=''.join(cape_data.split(':',1)[:1])\n",
    "            if t=='Station longitude':\n",
    "                a=''.join(cape_data.split(':',1)[1:])\n",
    "                longitude=float(a.replace(\" \", \"\"))\n",
    "            else:\n",
    "                cape_data=' '.join(cape1.splitlines()[5].split())\n",
    "                a=''.join(cape_data.split(':',1)[1:])\n",
    "                longitude=float(a.replace(\" \", \"\"))\n",
    "    return longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdbaca64-e9da-4267-bee7-0a9b6f6b976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the digit code txt file\n",
    "with open('digit code.txt','r') as f:\n",
    "    digit_code = f.read().splitlines()\n",
    "digit_code.remove('Europe')\n",
    "digit_code.remove('North America')\n",
    "digit_code.remove('South America')\n",
    "digit_code.remove('Southeast Asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2209cb67-877e-485c-b695-345eb48f9344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to return soup object from html file\n",
    "#input: year(string),month(string),day(string),code(string)\n",
    "#return: soup(Beautifulsoup)\n",
    "\n",
    "def get_soup(year,month,day,code):\n",
    "    soup=0\n",
    "    path='data/sounding?region=naconf&TYPE=TEXT:LIST&YEAR='+year+'&MONTH='+month+'&FROM='+day+'00&TO='+day+'00&STNM='+code\n",
    "    if os.path.exists(path):\n",
    "        with open(path,'rb') as f:\n",
    "            a=f.read()\n",
    "        soup= BeautifulSoup(a, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f6425f-8470-4951-9729-07cd47a15cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputï¼š one line of data(string)\n",
    "#return: pressure(float)\n",
    "\n",
    "def get_pres(data):\n",
    "    return float(data[0:7])\n",
    "\n",
    "#inputï¼š one line of data(string)\n",
    "#return: temperature(float)\n",
    "\n",
    "def get_temp(data):\n",
    "    return float(data[14:21])\n",
    "\n",
    "#inputï¼š one line of data(string)\n",
    "#return: mixing ratio(float)\n",
    "\n",
    "def get_humi(data):\n",
    "    return float(data[35:42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37792b7b-5cbe-4f24-9c5c-4b5674095411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get required variables from soup\n",
    "#input: soup(Beautifulsoup),year(string),month(string),day(string),code(string)\n",
    "#return: frame(Dataframe): a dataframe contains all the information required\n",
    "\n",
    "def get_input(soup,year,month,day,code):\n",
    "    frame=None\n",
    "    key={}\n",
    "    pre=soup.find_all('pre')\n",
    "    if pre:\n",
    "        cape=get_cape(soup)\n",
    "        data=pre[0].string\n",
    "        data_by_line=data.splitlines()\n",
    "        new_data_by_line=data_by_line[5:]\n",
    "        if len(new_data_by_line)>=20: \n",
    "            split_data_new=list(filter(lambda x: x[35:42].strip()!=\"\" and x[0:7].strip()!=\"\" and x[14:21].strip()!=\"\", new_data_by_line))\n",
    "            if len(split_data_new)!=0:\n",
    "                pres_list=list(map(get_pres,split_data_new))\n",
    "                temp_list=list(map(get_temp,split_data_new))\n",
    "                humi_list=list(map(get_humi,split_data_new))\n",
    "                if pres_list[-1]<=100:\n",
    "                    key['code']=[code]*len(split_data_new)\n",
    "                    key['year']=[year]*len(split_data_new)\n",
    "                    key['month']=[month]*len(split_data_new)\n",
    "                    key['day']=[day]*len(split_data_new)\n",
    "                    key['pres']=pres_list\n",
    "                    key['temp']=temp_list\n",
    "                    key['humi']=humi_list\n",
    "                    key['cape']=[cape]*len(split_data_new)\n",
    "# \n",
    "                    frame = pd.DataFrame(key)\n",
    "    return frame\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee821fb7-1877-4e67-b434-11aae488cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dates\n",
    "\n",
    "years=['2020','2019','2018','2017']\n",
    "months=['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "days=[]\n",
    "ddays=[]\n",
    "for i in range(9):\n",
    "    days.append('0'+str(i+1))\n",
    "    ddays.append('0'+str(i+1))\n",
    "for i in range(10):\n",
    "    days.append('1'+str(i))\n",
    "    ddays.append('1'+str(i))\n",
    "for i in range(10):\n",
    "    days.append('2'+str(i))\n",
    "    ddays.append('2'+str(i))\n",
    "leapdays=days.copy()\n",
    "noleapdays=days.copy()\n",
    "noleapdays.remove('29')\n",
    "days.append('30')\n",
    "days.append('31')\n",
    "ddays.append('30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f94dfac3-a513-43b0-ba68-d46c59c59265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the URLs\n",
    "\n",
    "url_list=[]\n",
    "for code in digit_code:\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            if month in ['01','03','05','07','08','10','12']:\n",
    "                for day in days:\n",
    "                    url='http://weather.uwyo.edu/cgi-bin/sounding?region=naconf&TYPE=TEXT%3ALIST&YEAR='+year+'&MONTH='\\\n",
    "                        +month+'&FROM='+day+'00&TO='+day+'00&STNM='+code\n",
    "                    data=[url,code,year,month,day]\n",
    "                    url_list.append(data)\n",
    "            elif month=='02':\n",
    "                if year=='2020':\n",
    "                    for day in leapdays:\n",
    "                        url='http://weather.uwyo.edu/cgi-bin/sounding?region=naconf&TYPE=TEXT%3ALIST&YEAR='+year+'&MONTH='\\\n",
    "                            +month+'&FROM='+day+'00&TO='+day+'00&STNM='+code\n",
    "                        data=[url,code,year,month,day]\n",
    "                        url_list.append(data)\n",
    "                else:\n",
    "                    for day in noleapdays:\n",
    "                        url='http://weather.uwyo.edu/cgi-bin/sounding?region=naconf&TYPE=TEXT%3ALIST&YEAR='+year+'&MONTH='\\\n",
    "                            +month+'&FROM='+day+'00&TO='+day+'00&STNM='+code\n",
    "                        data=[url,code,year,month,day]\n",
    "                        url_list.append(data)\n",
    "            else:\n",
    "                for day in ddays:\n",
    "                    url='http://weather.uwyo.edu/cgi-bin/sounding?region=naconf&TYPE=TEXT%3ALIST&YEAR='+year+'&MONTH='\\\n",
    "                            +month+'&FROM='+day+'00&TO='+day+'00&STNM='+code     \n",
    "                    data=[url,code,year,month,day]\n",
    "                    url_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "583f5077-a305-4262-9956-cdc947508344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to achieve interpolation\n",
    "# input: frame(Dataframe)\n",
    "# return: (dataframe(Dataframe),cape(float))\n",
    "\n",
    "def interp(frame):\n",
    "    original_pressure=frame['pres']\n",
    "    original_temperature=frame['temp']\n",
    "    original_humidity=frame['humi']\n",
    "    cape=frame['cape'][0]\n",
    "    min_p=np.min(frame['pres'])\n",
    "    max_p=np.max(frame['pres'])\n",
    "    delta_p = (max_p-min_p) /69\n",
    "    if delta_p==0:\n",
    "        my_pressures=np.array([min_p]*70)\n",
    "    else:\n",
    "        my_pressures= np.linspace(min_p, max_p,70)\n",
    "#         my_pressures=np.append(my_p,max_p)\n",
    "    temp_on_my_pressures=np.interp(my_pressures, np.flip(original_pressure), np.flip(original_temperature))\n",
    "    humi_on_my_pressures=np.interp(my_pressures, np.flip(original_pressure), np.flip(original_humidity))\n",
    "    f={}\n",
    "    f['pres']=my_pressures\n",
    "    f['temp']=temp_on_my_pressures\n",
    "    f['humi']=humi_on_my_pressures\n",
    "    dataframe = pd.DataFrame(f)\n",
    "    return (dataframe,cape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e418a9c7-1b33-45e3-b878-1bdc0d4a895f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.09008025077135665\r"
     ]
    }
   ],
   "source": [
    "# a loop to extract and create input data from URLs\n",
    "\n",
    "soup_list={}\n",
    "i=0\n",
    "for url in url_list:\n",
    "    i=i+1\n",
    "    code=url[1]\n",
    "    year=url[2]\n",
    "    month=url[3]\n",
    "    day=url[4]\n",
    "    string=code+year+month+day\n",
    "    soup=get_soup(year,month,day,code)\n",
    "#     print(string,end='\\r')\n",
    "    if soup!=0:\n",
    "        frame=get_input(soup,year,month,day,code)\n",
    "        if frame is not None:\n",
    "            if frame.empty==False:\n",
    "                value=interp(frame)\n",
    "                soup_list[string]=value\n",
    "    print(i/len(url_list)*100,end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d393301-83c9-48d6-aea1-042bb43249cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0868033836124434\r"
     ]
    }
   ],
   "source": [
    "# save input data as .txt files and save CAPE into .csv file\n",
    "#although this step is similar as the next cell, this step can easily access each files from the local machine\n",
    "\n",
    "f = open('cape.csv','w',)\n",
    "csv_writer = csv.writer(f)\n",
    "i=0\n",
    "count=0\n",
    "for key,value in soup_list.items():\n",
    "    i=i+1\n",
    "    data=np.c_[value[0]['temp'],value[0]['pres'],value[0]['humi']]\n",
    "    if value[1]!=\"No value\"and value[1]<3000:\n",
    "        np.savetxt('traindata/'+key,data,delimiter=',')\n",
    "        csv_writer.writerow((key,value[1]))\n",
    "        count=count+1\n",
    "    print(i/len(soup_list)*100,end='\\r')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8bad0cf-900f-4f87-9e54-b3041d1e33a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.828888888888885666\r"
     ]
    }
   ],
   "source": [
    "#store all input data into one .txt file, in order to prevent reloading all inputdata again and again\n",
    "#this step just is a trick to load the file\n",
    "\n",
    "f = csv.reader(open('cape.csv','r'))\n",
    "next(f)\n",
    "array=np.loadtxt('traindata/0601120200101',delimiter=',')\n",
    "count=1\n",
    "for e in f:\n",
    "    if float(e[1])<3000:\n",
    "        data=np.loadtxt('traindata/'+e[0],delimiter=',')\n",
    "        count=count+1\n",
    "        array=np.append(array,data)\n",
    "    print(count/900,end='\\r')\n",
    "np.savetxt('xvalues',array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1cf23f1-09ce-47b9-b4a0-17f144b3a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dict where key is the digit code and value is the lat and lon\n",
    "\n",
    "code_index={}\n",
    "i=0\n",
    "for code in digit_code:\n",
    "    for month in months[0:6]:\n",
    "        for day in days[0:10]:\n",
    "            year='2020'\n",
    "            soup=get_soup(year,month,day,code)\n",
    "            if soup!=0:\n",
    "                lat=get_latitude(soup)\n",
    "                lon=get_longitude(soup)\n",
    "                index=(lon,lat)\n",
    "                if code not in code_index:\n",
    "                    code_index[code]=index\n",
    "                if code in code_index and code_index[code]==('no value','no value'):\n",
    "                    code_index[code]=index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "847a04c9-1d39-4259-b7c2-8ab77f9dba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating position.csv file\n",
    "\n",
    "f = open('position.csv','w',)\n",
    "csv_writer = csv.writer(f)\n",
    "for key,value in code_index.items():\n",
    "    data=(key,value[0],value[1])\n",
    "    csv_writer.writerow(data)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
